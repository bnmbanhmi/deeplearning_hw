{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:06:00.921223Z",
     "iopub.status.busy": "2023-11-15T15:06:00.920846Z",
     "iopub.status.idle": "2023-11-15T15:06:12.740278Z",
     "shell.execute_reply": "2023-11-15T15:06:12.739071Z",
     "shell.execute_reply.started": "2023-11-15T15:06:00.921193Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:06:12.742797Z",
     "iopub.status.busy": "2023-11-15T15:06:12.742462Z",
     "iopub.status.idle": "2023-11-15T15:06:12.749938Z",
     "shell.execute_reply": "2023-11-15T15:06:12.749050Z",
     "shell.execute_reply.started": "2023-11-15T15:06:12.742767Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:06:12.751391Z",
     "iopub.status.busy": "2023-11-15T15:06:12.751112Z",
     "iopub.status.idle": "2023-11-15T15:06:13.794274Z",
     "shell.execute_reply": "2023-11-15T15:06:13.793256Z",
     "shell.execute_reply.started": "2023-11-15T15:06:12.751367Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:06:13.798286Z",
     "iopub.status.busy": "2023-11-15T15:06:13.797878Z",
     "iopub.status.idle": "2023-11-15T15:06:13.815884Z",
     "shell.execute_reply": "2023-11-15T15:06:13.814763Z",
     "shell.execute_reply.started": "2023-11-15T15:06:13.798248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, resize=None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.resize = resize\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(self.img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def read_mask(self, mask_path):\n",
    "        image = cv2.imread(mask_path)\n",
    "        image = cv2.resize(image, self.resize)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        lower1 = np.array([0, 100, 20])\n",
    "        upper1 = np.array([10, 255, 255])\n",
    "\n",
    "        lower2 = np.array([160,100,20])\n",
    "        upper2 = np.array([179,255,255])\n",
    "        lower_mask = cv2.inRange(image, lower1, upper1)\n",
    "        upper_mask = cv2.inRange(image, lower2, upper2)\n",
    "        \n",
    "        red_mask = lower_mask + upper_mask;\n",
    "        red_mask[red_mask != 0] = 1\n",
    "\n",
    "        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n",
    "        green_mask[green_mask != 0] = 2\n",
    "\n",
    "        full_mask = cv2.bitwise_or(red_mask, green_mask)\n",
    "        full_mask = np.expand_dims(full_mask, axis=-1) \n",
    "        full_mask = full_mask.astype(np.uint8)\n",
    "        \n",
    "        return full_mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        label_path = os.path.join(self.label_dir, self.images[idx])\n",
    "        image = cv2.imread(img_path)  # Đọc ảnh dưới dạng BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert sang RGB\n",
    "        label = self.read_mask(label_path)  \n",
    "        image = cv2.resize(image, self.resize)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "    def show_image(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        label_path = os.path.join(self.label_dir, self.images[idx])\n",
    "        image = plt.imread(img_path)\n",
    "        label = plt.imread(label_path)\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        axs[0].imshow(image)\n",
    "        axs[0].set_title('Image')\n",
    "        axs[1].imshow(label)\n",
    "        axs[1].set_title('Label')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:06:13.818080Z",
     "iopub.status.busy": "2023-11-15T15:06:13.817181Z",
     "iopub.status.idle": "2023-11-15T15:06:14.031863Z",
     "shell.execute_reply": "2023-11-15T15:06:14.030922Z",
     "shell.execute_reply.started": "2023-11-15T15:06:13.818043Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_path = []\n",
    "TRAIN_DIR = '/kaggle/input/bkai-igh-neopolyp/train/train'\n",
    "for root, dirs, files in os.walk(TRAIN_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        image_path.append(path)\n",
    "        \n",
    "len(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:06:14.033990Z",
     "iopub.status.busy": "2023-11-15T15:06:14.033311Z",
     "iopub.status.idle": "2023-11-15T15:06:14.210633Z",
     "shell.execute_reply": "2023-11-15T15:06:14.209692Z",
     "shell.execute_reply.started": "2023-11-15T15:06:14.033953Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mask_path = []\n",
    "TRAIN_MASK_DIR = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'\n",
    "for root, dirs, files in os.walk(TRAIN_MASK_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        mask_path.append(path)\n",
    "        \n",
    "len(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:06:14.214629Z",
     "iopub.status.busy": "2023-11-15T15:06:14.214302Z",
     "iopub.status.idle": "2023-11-15T15:06:14.220059Z",
     "shell.execute_reply": "2023-11-15T15:06:14.219163Z",
     "shell.execute_reply.started": "2023-11-15T15:06:14.214602Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = CustomImageDataset(img_dir= TRAIN_DIR,\n",
    "                             label_dir= TRAIN_MASK_DIR,\n",
    "                             resize= (256,256),\n",
    "                             transform = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:06:14.221762Z",
     "iopub.status.busy": "2023-11-15T15:06:14.221460Z",
     "iopub.status.idle": "2023-11-15T15:06:14.804642Z",
     "shell.execute_reply": "2023-11-15T15:06:14.803680Z",
     "shell.execute_reply.started": "2023-11-15T15:06:14.221737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"resnet34\",        \n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,                  \n",
    "    classes=3     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:06:14.806048Z",
     "iopub.status.busy": "2023-11-15T15:06:14.805764Z",
     "iopub.status.idle": "2023-11-15T15:06:43.463584Z",
     "shell.execute_reply": "2023-11-15T15:06:43.462537Z",
     "shell.execute_reply.started": "2023-11-15T15:06:14.806023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "images_data = []\n",
    "labels_data = []\n",
    "for x,y in dataset:\n",
    "    images_data.append(x)\n",
    "    labels_data.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:06:43.467330Z",
     "iopub.status.busy": "2023-11-15T15:06:43.467020Z",
     "iopub.status.idle": "2023-11-15T15:06:43.486242Z",
     "shell.execute_reply": "2023-11-15T15:06:43.485148Z",
     "shell.execute_reply.started": "2023-11-15T15:06:43.467303Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(CustomImageDataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.data[index]\n",
    "        label = self.targets[index]\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=label)\n",
    "            image = transformed['image'].float()\n",
    "            label = transformed['mask'].float()\n",
    "            label = label.permute(2, 0, 1)\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    \n",
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n",
    "    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "train_size = int(0.9 * len(images_data))\n",
    "val_size = len(images_data) - train_size\n",
    "train_dataset = CustomDataset(images_data[:train_size], labels_data[:train_size], transform=train_transform)\n",
    "val_dataset = CustomDataset(images_data[train_size:], labels_data[train_size:], transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:06:43.487902Z",
     "iopub.status.busy": "2023-11-15T15:06:43.487487Z",
     "iopub.status.idle": "2023-11-15T15:06:43.832487Z",
     "shell.execute_reply": "2023-11-15T15:06:43.831529Z",
     "shell.execute_reply.started": "2023-11-15T15:06:43.487874Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image,label = train_dataset[2]\n",
    "\n",
    "label_array = label.permute(1, 2, 0).numpy()\n",
    "image_array = image.permute(1, 2, 0).numpy()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].imshow(image_array)\n",
    "axs[0].set_title('Image')\n",
    "axs[0].axis('off')  \n",
    "\n",
    "axs[1].imshow(label_array)\n",
    "axs[1].set_title('Label')\n",
    "axs[1].axis('off')  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:06:43.834315Z",
     "iopub.status.busy": "2023-11-15T15:06:43.833969Z",
     "iopub.status.idle": "2023-11-15T15:06:43.842909Z",
     "shell.execute_reply": "2023-11-15T15:06:43.841987Z",
     "shell.execute_reply.started": "2023-11-15T15:06:43.834285Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:06:43.844466Z",
     "iopub.status.busy": "2023-11-15T15:06:43.844181Z",
     "iopub.status.idle": "2023-11-15T15:06:43.852827Z",
     "shell.execute_reply": "2023-11-15T15:06:43.851908Z",
     "shell.execute_reply.started": "2023-11-15T15:06:43.844441Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "color_dict= {0: (0, 0, 0),\n",
    "             1: (255, 0, 0),\n",
    "             2: (0, 255, 0)}\n",
    "def mask_to_rgb(mask, color_dict):\n",
    "    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "\n",
    "    for k in color_dict.keys():\n",
    "        output[mask==k] = color_dict[k]\n",
    "\n",
    "    return np.uint8(output)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:06:43.854406Z",
     "iopub.status.busy": "2023-11-15T15:06:43.854044Z",
     "iopub.status.idle": "2023-11-15T15:06:59.393075Z",
     "shell.execute_reply": "2023-11-15T15:06:59.391865Z",
     "shell.execute_reply.started": "2023-11-15T15:06:43.854373Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "import wandb\n",
    "!wandb login '7c74de70e64d4ae9ebc72e3d26a7847ac9337b3d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:06:59.395041Z",
     "iopub.status.busy": "2023-11-15T15:06:59.394702Z",
     "iopub.status.idle": "2023-11-15T15:07:33.644192Z",
     "shell.execute_reply": "2023-11-15T15:07:33.643331Z",
     "shell.execute_reply.started": "2023-11-15T15:06:59.395011Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project = 'Unet_polyp-Segmentation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:07:33.646147Z",
     "iopub.status.busy": "2023-11-15T15:07:33.645534Z",
     "iopub.status.idle": "2023-11-15T15:14:49.932133Z",
     "shell.execute_reply": "2023-11-15T15:14:49.930761Z",
     "shell.execute_reply.started": "2023-11-15T15:07:33.646110Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m150\u001b[39m\n\u001b[0;32m----> 3\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epochs = 150\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_val_loss = 999\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        pred = outputs.argmax(dim=1, keepdim=True)\n",
    "        train_accuracy += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_accuracy /= len(train_loader.dataset)\n",
    "    time_taken = time.time() - start_time\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            pred = outputs.argmax(dim=1, keepdim=True)\n",
    "            val_accuracy += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_accuracy /= len(val_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch}: Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Train Accuracy: {train_accuracy:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f} | \"\n",
    "        f\"Val Accuracy: {val_accuracy:.4f} | \"\n",
    "        f\"Time taken: {time_taken:.4f}\"\n",
    "    )\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'loss': val_loss,\n",
    "        }\n",
    "        save_path = 'colorization_model.pth'\n",
    "        torch.save(checkpoint, save_path)\n",
    "        print(\"New best checkpoint saved!\")\n",
    "\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_accuracy\": val_accuracy,\n",
    "    })\n",
    "\n",
    "    label = labels[0].cpu().numpy()\n",
    "    label = mask_to_rgb(label, color_dict)\n",
    "    outputs[0] = outputs[0].softmax(dim=0)\n",
    "    output = outputs[0].cpu().numpy()\n",
    "    output = np.argmax(output, axis=0)\n",
    "    output = mask_to_rgb(output, color_dict)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(label)\n",
    "    axs[0].set_title('Label')\n",
    "    axs[1].imshow(output)\n",
    "    axs[1].set_title('Output')\n",
    "    plt.show()\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:15:27.575431Z",
     "iopub.status.busy": "2023-11-15T15:15:27.574557Z",
     "iopub.status.idle": "2023-11-15T15:15:27.866220Z",
     "shell.execute_reply": "2023-11-15T15:15:27.865041Z",
     "shell.execute_reply.started": "2023-11-15T15:15:27.575388Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/kaggle/working/colorization_model.pth')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:15:32.170074Z",
     "iopub.status.busy": "2023-11-15T15:15:32.169197Z",
     "iopub.status.idle": "2023-11-15T15:15:33.185745Z",
     "shell.execute_reply": "2023-11-15T15:15:33.184651Z",
     "shell.execute_reply.started": "2023-11-15T15:15:32.170038Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!mkdir prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:24:25.064216Z",
     "iopub.status.busy": "2023-11-15T15:24:25.063878Z",
     "iopub.status.idle": "2023-11-15T15:24:47.730875Z",
     "shell.execute_reply": "2023-11-15T15:24:47.729764Z",
     "shell.execute_reply.started": "2023-11-15T15:24:25.064191Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainsize = 256\n",
    "model.eval()\n",
    "for i in os.listdir(\"/kaggle/input/bkai-igh-neopolyp/test/test\"):\n",
    "    img_path = os.path.join(\"/kaggle/input/bkai-igh-neopolyp/test/test\", i)\n",
    "    ori_img = cv2.imread(img_path)\n",
    "    ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n",
    "    ori_w = ori_img.shape[0]\n",
    "    ori_h = ori_img.shape[1]\n",
    "    img = cv2.resize(ori_img, (trainsize, trainsize))\n",
    "    transformed = val_transform(image=img)\n",
    "    input_img = transformed[\"image\"]\n",
    "    input_img = input_img.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output_mask = model.forward(input_img).squeeze(0).cpu().numpy().transpose(1,2,0)\n",
    "    mask = cv2.resize(output_mask, (ori_h, ori_w))\n",
    "    mask = np.argmax(mask, axis=2)\n",
    "    mask_rgb = mask_to_rgb(mask, color_dict)\n",
    "    mask_rgb = cv2.cvtColor(mask_rgb, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(\"prediction/{}\".format(i), mask_rgb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:24:47.733610Z",
     "iopub.status.busy": "2023-11-15T15:24:47.733177Z",
     "iopub.status.idle": "2023-11-15T15:24:50.808908Z",
     "shell.execute_reply": "2023-11-15T15:24:50.807739Z",
     "shell.execute_reply.started": "2023-11-15T15:24:47.733569Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_encode_one_mask(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels[pixels > 225] = 255\n",
    "    pixels[pixels <= 225] = 0\n",
    "    use_padding = False\n",
    "    if pixels[0] or pixels[-1]:\n",
    "        use_padding = True\n",
    "        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n",
    "        pixel_padded[1:-1] = pixels\n",
    "        pixels = pixel_padded\n",
    "    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    if use_padding:\n",
    "        rle = rle - 1\n",
    "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "    \n",
    "    return rle_to_string(rle)\n",
    "\n",
    "def rle2mask(mask_rle, shape=(3,3)):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2string(dir):\n",
    "    strings = []\n",
    "    ids = []\n",
    "    ws, hs = [[] for i in range(2)]\n",
    "    for image_id in os.listdir(dir):\n",
    "        id = image_id.split('.')[0]\n",
    "        path = os.path.join(dir, image_id)\n",
    "        print(path)\n",
    "        img = cv2.imread(path)[:,:,::-1]\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        for channel in range(2):\n",
    "            ws.append(w)\n",
    "            hs.append(h)\n",
    "            ids.append(f'{id}_{channel}')\n",
    "            string = rle_encode_one_mask(img[:,:,channel])\n",
    "            strings.append(string)\n",
    "    r = {\n",
    "        'ids': ids,\n",
    "        'strings': strings,\n",
    "    }\n",
    "    return r\n",
    "\n",
    "\n",
    "MASK_DIR_PATH = '/kaggle/working/prediction'\n",
    "dir = MASK_DIR_PATH\n",
    "res = mask2string(dir)\n",
    "df = pd.DataFrame(columns=['Id', 'Expected'])\n",
    "df['Id'] = res['ids']\n",
    "df['Expected'] = res['strings']\n",
    "\n",
    "df.to_csv(r'output.csv', index=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 2715462,
     "sourceId": 30892,
     "sourceType": "competition"
    },
    {
     "datasetId": 4007626,
     "sourceId": 6974612,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30580,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "deeplearning_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
